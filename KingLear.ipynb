{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analysis of Alasdair Beckett-King's Lear\n",
    "\n",
    "![ABK](abk.jpg)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To practice using Python, I'm going to try and find the top 115 most frequently used words in \"King Lear\".\n",
    "\n",
    "The reason for this choice is that comedian Alasdair Beckett-King once performed a reading of the top 115 most frequently used words in \"King Lear\" as if it was a genuine Shakespeare play. The funny thing about it was that you couldn't tell that he was just saying a bunch of random Shakespearian words, rather than reading from an actual script. \n",
    "\n",
    "[Here's the skit](https://www.youtube.com/watch?v=ZkIrDMLDDjs): \n",
    "\n",
    "But did he *really* recite the actual top 115 words from Lear? Let's find out."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 0) PREPARE ENVIRONMENT\n",
    "from urllib.request import urlopen\n",
    "import string\n",
    "\n",
    "# Google Colab libraries\n",
    "# from google.colab import files\n",
    "# from IPython.display import Image\n",
    "# from IPython.display set_matplotlib_formats\n",
    "# set_matplotlib_formats('pdf', 'svg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1) Get Data\n",
    "Let's get the data from Project Gutenberg, which has King Lear in both HTML and txt format. I'm going to get the .txt file because I'm lazy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Number of words in the text file is:  30802\n"
     ]
    }
   ],
   "source": [
    "# Download King Lear from Project Gutenberg\n",
    "filepath = urlopen(\"https://www.gutenberg.org/files/1532/1532-0.txt\")\n",
    "data = filepath.read()\n",
    "words = data.split()\n",
    "print('Number of words in the text file is: ', len(words))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "My word is: b'pen'\n",
      "The type of word my word is is: <class 'bytes'>\n"
     ]
    }
   ],
   "source": [
    "# Explore data, choosing a word at random and seeing what it looks like\n",
    "my_word = words[15400]\n",
    "print(\"My word is: \" + str(my_word))\n",
    "print(\"The type of word my word is is: \" + str(type(my_word)))"
   ]
  },
  {
   "source": [
    "Hmmm. Each word is in a weird format called \"bytes\"."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2) Tidy Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2a. Clean the Text\n",
    "There are a few problems with the text:\n",
    "* **Type** - Each word starts with the letter b. This means it's a bytes type not a string, so we can't do normal string things to it until we convert it.\n",
    "* **Case** - We should make everything lower case.\n",
    "* **Punctuation** - There's a whole heap of punctuation and brackets etc which should be removed.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "My word is: pen\nMy type is: <class 'str'>\n"
     ]
    }
   ],
   "source": [
    "# Tidy up\n",
    "preclean = []\n",
    "for word in words:\n",
    "    # Convert from bytes to string\n",
    "    w = word.decode()\n",
    "\n",
    "    # Convert to lowercase and remove punctuation\n",
    "    w = w.lower()\n",
    "    w = ''.join([letter for letter in w if not letter in string.punctuation])\n",
    "\n",
    "    preclean.append(w)\n",
    "my_word = preclean[15400]\n",
    "print(\"My word is: \" + str(my_word))\n",
    "print(\"My type is: \" + str(type(my_word)))"
   ]
  },
  {
   "source": [
    "That's better. Now our text is in a more manageable string format."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2b. Remove Non-Shakespeare Text  \n",
    "\n",
    "Looking at the [website](https://www.gutenberg.org/files/1532/1532-h/1532-h.htm),Project Gutenberg has added a preamble just before the play starts which we need to remove. They've also added some stuff at the end. Luckily, Python allows us to tidy this up with a couple of split() commands. \n",
    "\n",
    "The play starts just after the first use of the word \"twenty Project Gutenberg volunteers\". It ends just before the words \"End of Project Gutenberg's King Lear\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Word count: 27680\nTHE FIRST TEN WORDS\n['the', 'tragedy', 'of', 'king', 'lear', 'by', 'william', 'shakespeare', 'contents', 'act']\nTHE LAST TEN WORDS\n['much', 'nor', 'live', 'so', 'long', 'exeunt', 'with', 'a', 'dead', 'march']\n"
     ]
    }
   ],
   "source": [
    "# Join the corpus back together again\n",
    "removing = ' '.join(preclean)\n",
    "removed = removing.split(\"volunteers\")[1].split(\"end of project\")[0]\n",
    "removed = removed.split()\n",
    "\n",
    "print(\"Word count: \" + str(len(removed)))\n",
    "print(\"THE FIRST TEN WORDS\")\n",
    "print(removed[0:10])\n",
    "\n",
    "print(\"THE LAST TEN WORDS\")\n",
    "print(removed[-10:])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2c. Remove Names\n",
    "\n",
    "The final problem is that there are some proper names, like \"Lear\" and \"Cordelia\" which aren't really words. We should remove them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Word count before edit : 27680\nTHE FIRST TEN WORDS\n['the', 'tragedy', 'of', 'king', 'by', 'contents', 'act', 'i', 'scene', 'i']\nTHE LAST TEN WORDS\n['much', 'nor', 'live', 'so', 'long', 'exeunt', 'with', 'a', 'dead', 'march']\nWord count after edit: 26354\n"
     ]
    }
   ],
   "source": [
    "list_of_names = [\n",
    "    \"lear\", \"burgundy\", \"cornwall\", \"albany\", \"kent\", \"gloucester\",\n",
    "    \"edgar\", \"edmund\", \"curan\", \"oswald\", \"goneril\", \"regan\", \n",
    "    \"cordelia\", \"william\", \"shakespeare\"\n",
    "]\n",
    "\n",
    "clean = [word for word in removed if not word in list_of_names]\n",
    "\n",
    "print(\"Word count before edit : \" + str(len(removed)))\n",
    "print(\"THE FIRST TEN WORDS\")\n",
    "print(clean[0:10])\n",
    "\n",
    "print(\"THE LAST TEN WORDS\")\n",
    "print(clean[-10:])\n",
    "print(\"Word count after edit: \" + str(len(clean)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3) Analyse Data\n",
    "\n",
    "## 3a. Sort\n",
    "Let's get a list of all the words in frequency order.\n",
    "\n",
    "The original words of the skit are as follows:"
   ]
  },
  {
   "source": [
    "*The and I, to of you my, a that in not this me your thou is his.*  \n",
    "*Have him with it! He be thy for no so. Thee.*    *laughs*  \n",
    "*What her will but are as do, Sir Our.*  \n",
    "*Fool! If all on shall Lord, from come by am good.*    \n",
    "*O more where now which we let man know.*  \n",
    "\n",
    "*Out! I'll how well. Who then King there take? Or hear would father?*\n",
    "*They at go. Old hath they why she most may yet there make!*  \n",
    "*Tis was us. Love see must heart upon seek poor. Like, then genetlemen.*\n",
    "*Should such what I'm give art one, nor had these can some say.*   \n",
    "\n",
    "*Eyes away. Night! Nature! To nothing!\"*\n",
    "\n",
    "Let's see if the original text has the same word frequencies."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "['the', 'and', 'i', 'to', 'of', 'you', 'my', 'a', 'that', 'in', 'not', 'this', 'me', 'your', 'is', 'thou', 'his', 'with', 'have', 'him', 'it', 'he', 'be', 'thy', 'for', 'no', 'thee', 'what', 'so', 'her', 'but', 'are', 'will', 'as', 'fool', 'our', 'sir', 'if', 'do', 'on', 'all', 'shall', 'lord', 'from', 'by', 'come', 'am', 'which', 'good', 'more', 'when', 'o', 'now', 'know', 'let', 'we', 'king', 'man', 'enter', 'out', 'i’ll', 'who', 'how', 'or', 'than', 'their', 'here', 'well', 'father', 'take', 'they', 'would', 'at', 'go', 'old', 'there', 'hath', 'make', 'scene', 'gentleman', 'may', 'us', 'most', 'she', 'yet', 'was', 'love', '’tis', 'them', 'why', 'see', 'must', 'speak', 'poor', 'upon', 'an', 'should', 'heart', 'then', 'like', 'exit', 'such', 'where', 'give', 'art', 'one', 'had', 'eyes', 'can', 'some', 'away', 'these', 'say', 'life', 'nature', 'nor', 'exeunt', 'nothing', 'too', 'up']\n"
     ]
    }
   ],
   "source": [
    "from collections import defaultdict\n",
    "wordCount = defaultdict(int)\n",
    "for word in clean:\n",
    "    wordCount[word] += 1\n",
    "\n",
    "# Prints words in descending order, so we can read them \n",
    "result = sorted(wordCount, key=wordCount.__getitem__, reverse=True)[:120]\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3b. Wha????\n",
    "\n",
    "Wait a minute. Those aren't the words he used in his script! Well, many of them are, but they're not exactly the same. \n",
    "\n",
    "Could it be that some of the words appear the same number of times as each other, which would lead to some small discrepancies? \n",
    "\n",
    "Let's see print each word along with its frequency."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "[(921, 'the'),\n",
       " (738, 'and'),\n",
       " (622, 'i'),\n",
       " (570, 'to'),\n",
       " (494, 'of'),\n",
       " (456, 'you'),\n",
       " (454, 'my'),\n",
       " (422, 'a'),\n",
       " (336, 'that'),\n",
       " (314, 'in'),\n",
       " (280, 'not'),\n",
       " (234, 'this'),\n",
       " (225, 'me'),\n",
       " (222, 'your'),\n",
       " (219, 'is'),\n",
       " (216, 'thou'),\n",
       " (210, 'his'),\n",
       " (206, 'with'),\n",
       " (206, 'have'),\n",
       " (200, 'him'),\n",
       " (193, 'it'),\n",
       " (174, 'he'),\n",
       " (165, 'be'),\n",
       " (158, 'thy'),\n",
       " (153, 'for'),\n",
       " (152, 'no'),\n",
       " (138, 'thee'),\n",
       " (136, 'what'),\n",
       " (134, 'so'),\n",
       " (131, 'her'),\n",
       " (130, 'but'),\n",
       " (127, 'will'),\n",
       " (127, 'are'),\n",
       " (123, 'as'),\n",
       " (119, 'fool'),\n",
       " (115, 'our'),\n",
       " (113, 'sir'),\n",
       " (112, 'if'),\n",
       " (108, 'do'),\n",
       " (104, 'on'),\n",
       " (101, 'all'),\n",
       " (98, 'shall'),\n",
       " (97, 'lord'),\n",
       " (94, 'from'),\n",
       " (91, 'by'),\n",
       " (88, 'come'),\n",
       " (86, 'am'),\n",
       " (83, 'which'),\n",
       " (83, 'good'),\n",
       " (82, 'more'),\n",
       " (79, 'when'),\n",
       " (77, 'o'),\n",
       " (76, 'now'),\n",
       " (76, 'let'),\n",
       " (76, 'know'),\n",
       " (75, 'we'),\n",
       " (74, 'king'),\n",
       " (73, 'man'),\n",
       " (73, 'enter'),\n",
       " (72, 'out'),\n",
       " (70, 'i’ll'),\n",
       " (69, 'who'),\n",
       " (69, 'how'),\n",
       " (68, 'or'),\n",
       " (67, 'than'),\n",
       " (66, 'well'),\n",
       " (66, 'their'),\n",
       " (66, 'here'),\n",
       " (65, 'father'),\n",
       " (64, 'take'),\n",
       " (63, 'would'),\n",
       " (63, 'they'),\n",
       " (60, 'at'),\n",
       " (59, 'go'),\n",
       " (57, 'old'),\n",
       " (56, 'there'),\n",
       " (55, 'hath'),\n",
       " (54, 'make'),\n",
       " (53, 'scene'),\n",
       " (53, 'may'),\n",
       " (53, 'gentleman'),\n",
       " (52, '’tis'),\n",
       " (52, 'yet'),\n",
       " (52, 'was'),\n",
       " (52, 'us'),\n",
       " (52, 'she'),\n",
       " (52, 'most'),\n",
       " (52, 'love'),\n",
       " (51, 'why'),\n",
       " (51, 'them'),\n",
       " (50, 'see'),\n",
       " (49, 'must'),\n",
       " (48, 'upon'),\n",
       " (48, 'speak'),\n",
       " (48, 'poor'),\n",
       " (47, 'should'),\n",
       " (47, 'an'),\n",
       " (46, 'then'),\n",
       " (46, 'heart'),\n",
       " (44, 'such'),\n",
       " (44, 'like'),\n",
       " (44, 'exit'),\n",
       " (43, 'where'),\n",
       " (42, 'give'),\n",
       " (41, 'one'),\n",
       " (41, 'art'),\n",
       " (39, 'had'),\n",
       " (39, 'eyes'),\n",
       " (38, 'these'),\n",
       " (38, 'some'),\n",
       " (38, 'can'),\n",
       " (38, 'away'),\n",
       " (37, 'say'),\n",
       " (37, 'life'),\n",
       " (36, 'nor'),\n",
       " (36, 'nature'),\n",
       " (34, 'nothing'),\n",
       " (34, 'exeunt'),\n",
       " (33, 'too'),\n",
       " (32, 'up')]"
      ]
     },
     "metadata": {},
     "execution_count": 8
    }
   ],
   "source": [
    "# Show the result with their frequencies\n",
    "unsorted = [(wordCount[word], word) for word in wordCount]\n",
    "result = sorted(unsorted, reverse = True)\n",
    "result[:120]\n",
    "# tl;dr No, that's not it"
   ]
  },
  {
   "source": [
    "It isn't. Only a couple of pairs of words occur the same number of times. "
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4 Conclusion\n",
    "\n",
    "Alasdair has taken some poetic license with the word frequencies to make it easier to perform and to flow better. \n",
    "\n",
    "Alas, there's more to being a hilarious YouTube star than programming word frequencies in Python. You have to have talent as well. All my dreams are dashed."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
